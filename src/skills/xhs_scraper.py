"""
XHS Scraper Skillï¼ˆLayer 2 æ ‡å‡†æŠ€èƒ½ï¼‰
å°çº¢ä¹¦å¸–å­æ•°æ®é‡‡é›†ï¼šæ‰“å¼€å°çº¢ä¹¦é“¾æ¥ï¼Œæå–å¸–å­æ ‡é¢˜ã€æ­£æ–‡ã€è¯„è®ºã€äº’åŠ¨æ•°æ®ç­‰ï¼Œ
ä¿å­˜ä¸ºç»“æ„åŒ– Markdown æ–‡ä»¶ã€‚

ä¾èµ– Layer 1 å·¥å…·ï¼šplaywright_toolsï¼ˆopen_browser, get_page_text ç­‰ï¼‰
"""

import os
import json
import time
import re
from datetime import datetime
from typing import Optional

SKILL_NAME = "xhs_scraper"
SKILL_DESCRIPTION = "å°çº¢ä¹¦å¸–å­æ•°æ®é‡‡é›†ï¼šè‡ªåŠ¨æ‰“å¼€å°çº¢ä¹¦é“¾æ¥ï¼Œæå–å¸–å­æ ‡é¢˜ã€æ­£æ–‡ã€è¯„è®ºã€äº’åŠ¨æ•°æ®ç­‰ï¼Œä¿å­˜ä¸ºç»“æ„åŒ–æ–‡ä»¶ã€‚å‚æ•°ï¼šurl(å¿…å¡«), collect_account(å¯é€‰,é»˜è®¤False), max_comments(å¯é€‰,é»˜è®¤50)"

# é¡¹ç›®æ ¹ç›®å½•
_PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# LLM è§£æ Prompt
_EXTRACT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®æå–ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯å°çº¢ä¹¦å¸–å­é¡µé¢çš„åŸå§‹æ–‡æœ¬ã€‚
è¯·ä»ä¸­æå–ä»¥ä¸‹ç»“æ„åŒ–ä¿¡æ¯å¹¶è¿”å›**çº¯ JSON**ï¼ˆä¸è¦ç”¨ markdown ä»£ç å—åŒ…è£¹ï¼‰ï¼š

{
  "title": "å¸–å­æ ‡é¢˜",
  "author": "ä½œè€…æ˜µç§°",
  "publish_time": "å‘å¸ƒæ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼‰",
  "post_type": "å›¾æ–‡ / è§†é¢‘ / çº¯æ–‡å­—",
  "content": "å¸–å­æ­£æ–‡å†…å®¹ï¼ˆå®Œæ•´æå–ï¼‰",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
  "likes": 0,
  "favorites": 0,
  "comment_count": 0,
  "comments": [
    {"user": "ç”¨æˆ·å", "content": "è¯„è®ºå†…å®¹", "likes": 0}
  ]
}

æ³¨æ„ï¼š
1. æ•°å­—å­—æ®µï¼ˆlikes, favorites, comment_countï¼‰è¯·è½¬ä¸ºæ•´æ•°ï¼Œå¦‚ "1.2ä¸‡" è½¬ä¸º 12000
2. å¦‚æœæŸä¸ªå­—æ®µæ— æ³•æå–ï¼Œè®¾ä¸º null
3. comments æ•°ç»„ä¸­åªåŒ…å«èƒ½è¯†åˆ«å‡ºçš„è¯„è®º
4. åªè¿”å› JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Š

ä»¥ä¸‹æ˜¯é¡µé¢åŸå§‹æ–‡æœ¬ï¼š
"""

_ACCOUNT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®æå–ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯å°çº¢ä¹¦ç”¨æˆ·ä¸»é¡µçš„åŸå§‹æ–‡æœ¬ã€‚
è¯·æå–ä»¥ä¸‹ä¿¡æ¯å¹¶è¿”å›**çº¯ JSON**ï¼ˆä¸è¦ç”¨ markdown ä»£ç å—åŒ…è£¹ï¼‰ï¼š

{
  "nickname": "æ˜µç§°",
  "xiaohongshu_id": "å°çº¢ä¹¦å·",
  "followers": 0,
  "following": 0,
  "total_likes_and_favorites": 0,
  "bio": "ä¸ªäººç®€ä»‹"
}

æ³¨æ„ï¼šæ•°å­—è¯·è½¬ä¸ºæ•´æ•°ã€‚åªè¿”å› JSONã€‚

ä»¥ä¸‹æ˜¯é¡µé¢åŸå§‹æ–‡æœ¬ï¼š
"""


def _parse_number(text: str) -> int:
    """å°†ä¸­æ–‡æ•°å­—è¡¨è¾¾ï¼ˆå¦‚ '1.2ä¸‡'ï¼‰è½¬ä¸ºæ•´æ•°"""
    if not text:
        return 0
    text = text.strip()
    try:
        if 'ä¸‡' in text:
            return int(float(text.replace('ä¸‡', '')) * 10000)
        elif 'äº¿' in text:
            return int(float(text.replace('äº¿', '')) * 100000000)
        else:
            return int(re.sub(r'[^\d]', '', text) or 0)
    except:
        return 0


def _call_llm(prompt: str, text: str) -> dict:
    """è°ƒç”¨ LLM è§£ææ–‡æœ¬ä¸ºç»“æ„åŒ– JSON"""
    from src.core.llm_manager import LLMManager

    # å°è¯•åŠ è½½ç”¨æˆ·çº§é…ç½®
    config_path = None
    data_dir = os.path.join(_PROJECT_ROOT, "data")
    # æ‰«æç”¨æˆ·ç›®å½•å¯»æ‰¾ llm_providers.json
    for item in os.listdir(data_dir):
        user_config = os.path.join(data_dir, item, "llm_providers.json")
        if os.path.exists(user_config):
            config_path = user_config
            break

    mgr = LLMManager(config_path=config_path) if config_path else LLMManager()

    # å°è¯•è·å–ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹
    model = None
    for provider in mgr.providers.values():
        try:
            model_name = provider.models[0] if provider.models else None
            if model_name:
                model = mgr.get_model(provider.id, model_name, temperature=0.1)
                break
        except:
            continue

    if not model:
        raise RuntimeError("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„ LLM æ¨¡å‹ã€‚è¯·æ£€æŸ¥ LLM Provider é…ç½®ã€‚")

    # æˆªæ–­è¾“å…¥é˜²æ­¢ token è¶…é™
    max_text_len = 12000
    if len(text) > max_text_len:
        text = text[:max_text_len] + "\n...[æ–‡æœ¬å·²æˆªæ–­]"

    response = model.invoke(prompt + text)
    content = response.content if hasattr(response, 'content') else str(response)

    # å°è¯•ä»å“åº”ä¸­æå– JSON
    # å¤„ç†å¯èƒ½è¢« markdown ä»£ç å—åŒ…è£¹çš„æƒ…å†µ
    json_match = re.search(r'```(?:json)?\s*([\s\S]*?)```', content)
    if json_match:
        content = json_match.group(1)

    # æ¸…ç†å¹¶è§£æ
    content = content.strip()
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
        start = content.find('{')
        end = content.rfind('}')
        if start >= 0 and end > start:
            try:
                return json.loads(content[start:end + 1])
            except:
                pass
        return {"error": "LLM è¿”å›å†…å®¹æ— æ³•è§£æä¸º JSON", "raw": content[:500]}


def _format_markdown(data: dict, url: str, account_data: dict = None) -> str:
    """å°†ç»“æ„åŒ–æ•°æ®æ ¼å¼åŒ–ä¸º Markdown"""
    lines = []

    title = data.get("title", "æœªçŸ¥æ ‡é¢˜")
    lines.append(f"# {title}")
    lines.append("")

    # åŸºæœ¬ä¿¡æ¯
    lines.append("## åŸºæœ¬ä¿¡æ¯")
    lines.append(f"- **ä½œè€…**: {data.get('author', 'æœªçŸ¥')}")
    lines.append(f"- **å‘å¸ƒæ—¶é—´**: {data.get('publish_time', 'æœªçŸ¥')}")
    lines.append(f"- **å¸–å­ç±»å‹**: {data.get('post_type', 'æœªçŸ¥')}")
    likes = data.get('likes', 0)
    favs = data.get('favorites', 0)
    comments_count = data.get('comment_count', 0)
    lines.append(f"- **äº’åŠ¨æ•°æ®**: ğŸ‘ {likes} | â­ {favs} | ğŸ’¬ {comments_count}")
    lines.append(f"- **åŸå§‹é“¾æ¥**: {url}")
    lines.append(f"- **é‡‡é›†æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")

    # å¸–å­æ­£æ–‡
    lines.append("## å¸–å­æ­£æ–‡")
    content = data.get("content", "")
    if not content or content == "null":
        content = "[æœªèƒ½æå–æ­£æ–‡å†…å®¹]"
    lines.append(content)
    lines.append("")

    # æ ‡ç­¾
    tags = data.get("tags", [])
    if tags:
        lines.append("## æ ‡ç­¾")
        lines.append(" ".join([f"#{t}" for t in tags]))
        lines.append("")

    # è¯„è®º
    comments = data.get("comments", [])
    lines.append(f"## è¯„è®º (å·²é‡‡é›† {len(comments)} æ¡)")
    if comments:
        for i, c in enumerate(comments, 1):
            user = c.get("user", "åŒ¿å")
            text = c.get("content", "")
            c_likes = c.get("likes", 0)
            lines.append(f"{i}. **{user}**: {text} (ğŸ‘ {c_likes})")
    else:
        lines.append("æš‚æ— è¯„è®ºæ•°æ®ã€‚")
    lines.append("")

    # è´¦å·æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
    if account_data and not account_data.get("error"):
        lines.append("## ä½œè€…è´¦å·ä¿¡æ¯")
        lines.append(f"- **æ˜µç§°**: {account_data.get('nickname', 'æœªçŸ¥')}")
        lines.append(f"- **å°çº¢ä¹¦å·**: {account_data.get('xiaohongshu_id', 'æœªçŸ¥')}")
        lines.append(f"- **ç²‰ä¸æ•°**: {account_data.get('followers', 0)}")
        lines.append(f"- **å…³æ³¨æ•°**: {account_data.get('following', 0)}")
        lines.append(f"- **è·èµä¸æ”¶è—**: {account_data.get('total_likes_and_favorites', 0)}")
        bio = account_data.get('bio', '')
        if bio:
            lines.append(f"- **ç®€ä»‹**: {bio}")
        lines.append("")

    return "\n".join(lines)


def _sanitize_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    # ç§»é™¤ Windows ä¸å…è®¸çš„å­—ç¬¦
    name = re.sub(r'[<>:"/\\|?*]', '', name)
    # ç§»é™¤å‰åç©ºç™½å’Œç‚¹
    name = name.strip().strip('.')
    # é™åˆ¶é•¿åº¦
    if len(name) > 80:
        name = name[:80]
    return name or "untitled"


def run(url: str, collect_account: bool = False, max_comments: int = 50, **kwargs) -> str:
    """
    é‡‡é›†å°çº¢ä¹¦å¸–å­æ•°æ®

    Args:
        url: å°çº¢ä¹¦å¸–å­é“¾æ¥
        collect_account: æ˜¯å¦åŒæ—¶é‡‡é›†ä½œè€…è´¦å·æ•°æ®ï¼ˆç²‰ä¸æ•°ç­‰ï¼‰
        max_comments: æœ€å¤šé‡‡é›†è¯„è®ºæ•°é‡ï¼Œé»˜è®¤ 50 æ¡
    """
    from src.tools.playwright_tools import (
        _ensure_page, _current_page, close_browser,
        PLAYWRIGHT_TOOLS
    )
    import src.tools.playwright_tools as pw_module

    results_log = []

    try:
        # ============================================
        # Step 1: æ‰“å¼€æµè§ˆå™¨
        # ============================================
        results_log.append("[1/7] æ­£åœ¨æ‰“å¼€æµè§ˆå™¨...")
        page = _ensure_page(url, browser="msedge")
        results_log.append(f"  âœ“ å·²å¯¼èˆªåˆ°: {url}")

        # ç­‰å¾…é¡µé¢åŠ è½½
        page.wait_for_timeout(3000)

        # ============================================
        # Step 2: æ£€æµ‹ç™»å½•çŠ¶æ€
        # ============================================
        results_log.append("[2/7] æ£€æµ‹ç™»å½•çŠ¶æ€...")

        # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•å¼¹çª—
        login_detected = False
        login_selectors = [".login-container", ".qrcode-img", "[class*='login-btn']"]
        for sel in login_selectors:
            try:
                el = page.query_selector(sel)
                if el and el.is_visible():
                    login_detected = True
                    break
            except:
                continue

        if login_detected:
            results_log.append("  âš  æœªç™»å½•ï¼Œè¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨ä¸­æ‰«ç ç™»å½•å°çº¢ä¹¦")
            results_log.append("  â³ ç­‰å¾…ç™»å½•ä¸­ï¼ˆæœ€å¤š 120 ç§’ï¼‰...")

            # è½®è¯¢ç­‰å¾…ç™»å½•å®Œæˆ
            start_time = time.time()
            logged_in = False
            while time.time() - start_time < 120:
                time.sleep(3)
                # æ£€æŸ¥ç™»å½•å¼¹çª—æ˜¯å¦æ¶ˆå¤±
                still_login = False
                for sel in login_selectors:
                    try:
                        el = page.query_selector(sel)
                        if el and el.is_visible():
                            still_login = True
                            break
                    except:
                        continue
                if not still_login:
                    logged_in = True
                    break

            if not logged_in:
                return "âŒ ç™»å½•è¶…æ—¶ã€‚è¯·æ‰‹åŠ¨ç™»å½•åé‡è¯•ã€‚\n\n" + "\n".join(results_log)

            results_log.append("  âœ“ ç™»å½•æˆåŠŸï¼")
            # é‡æ–°å¯¼èˆªåˆ°ç›®æ ‡é¡µé¢
            page.goto(url, wait_until="domcontentloaded", timeout=30000)
            page.wait_for_timeout(3000)
        else:
            results_log.append("  âœ“ å·²å¤„äºç™»å½•çŠ¶æ€")

        # ============================================
        # Step 3: ç­‰å¾…å¸–å­å†…å®¹åŠ è½½
        # ============================================
        results_log.append("[3/7] ç­‰å¾…å¸–å­å†…å®¹åŠ è½½...")
        page.wait_for_timeout(2000)
        results_log.append("  âœ“ é¡µé¢å·²åŠ è½½")

        # ============================================
        # Step 4: æ»šåŠ¨åŠ è½½è¯„è®º
        # ============================================
        results_log.append(f"[4/7] æ»šåŠ¨åŠ è½½è¯„è®º (æœ€å¤š {max_comments} æ¡)...")
        scroll_attempts = min(max_comments // 5, 15)  # ä¼°ç®—éœ€è¦æ»šåŠ¨æ¬¡æ•°
        for i in range(scroll_attempts):
            page.evaluate("window.scrollBy(0, 800)")
            page.wait_for_timeout(1500)
        results_log.append(f"  âœ“ å®Œæˆ {scroll_attempts} æ¬¡æ»šåŠ¨")

        # ============================================
        # Step 5: æå–é¡µé¢æ–‡æœ¬
        # ============================================
        results_log.append("[5/7] æå–é¡µé¢æ–‡æœ¬...")
        page_text = page.inner_text("body")

        if not page_text or len(page_text) < 50:
            return "âŒ é¡µé¢å†…å®¹æå–å¤±è´¥ï¼Œå¯èƒ½é¡µé¢æœªæ­£ç¡®åŠ è½½ã€‚\n\n" + "\n".join(results_log)

        results_log.append(f"  âœ“ è·å–åˆ° {len(page_text)} å­—ç¬¦")

        # ============================================
        # Step 6: LLM ç»“æ„åŒ–è§£æ
        # ============================================
        results_log.append("[6/7] è°ƒç”¨ LLM è§£ææ•°æ®...")
        post_data = _call_llm(_EXTRACT_PROMPT, page_text)

        if post_data.get("error"):
            results_log.append(f"  âš  LLM è§£æå¼‚å¸¸: {post_data['error']}")
        else:
            results_log.append(f"  âœ“ è§£ææˆåŠŸ: {post_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}")

        # å¯é€‰ï¼šé‡‡é›†è´¦å·æ•°æ®
        account_data = None
        if collect_account:
            results_log.append("[6.5/7] é‡‡é›†ä½œè€…è´¦å·æ•°æ®...")
            try:
                # å°è¯•ç‚¹å‡»ä½œè€…å¤´åƒ/é“¾æ¥
                author_selectors = [
                    "a.author-wrapper",
                    ".author-container a",
                    "a[href*='/user/profile']",
                    ".note-user a",
                ]
                clicked = False
                for sel in author_selectors:
                    try:
                        el = page.query_selector(sel)
                        if el:
                            href = el.get_attribute("href")
                            if href:
                                if href.startswith("/"):
                                    href = "https://www.xiaohongshu.com" + href
                                page.goto(href, wait_until="domcontentloaded", timeout=15000)
                                page.wait_for_timeout(3000)
                                clicked = True
                                break
                    except:
                        continue

                if clicked:
                    account_text = page.inner_text("body")
                    account_data = _call_llm(_ACCOUNT_PROMPT, account_text)
                    results_log.append(f"  âœ“ è´¦å·æ•°æ®é‡‡é›†æˆåŠŸ")
                else:
                    results_log.append("  âš  æœªæ‰¾åˆ°ä½œè€…ä¸»é¡µé“¾æ¥")
            except Exception as e:
                results_log.append(f"  âš  è´¦å·æ•°æ®é‡‡é›†å¤±è´¥: {e}")

        # ============================================
        # Step 7: ä¿å­˜æ–‡ä»¶
        # ============================================
        results_log.append("[7/7] ä¿å­˜æ•°æ®æ–‡ä»¶...")

        title = post_data.get("title", "æœªçŸ¥æ ‡é¢˜")
        filename = _sanitize_filename(title) + ".md"

        markdown_content = _format_markdown(post_data, url, account_data)

        # ä¿å­˜åˆ° data/.xhs_data/ ç›®å½•
        save_dir = os.path.join(_PROJECT_ROOT, "data", ".xhs_data")
        os.makedirs(save_dir, exist_ok=True)
        filepath = os.path.join(save_dir, filename)

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(markdown_content)

        results_log.append(f"  âœ“ æ–‡ä»¶å·²ä¿å­˜: {filepath}")

        # å…³é—­æµè§ˆå™¨
        try:
            close_browser.invoke({})
        except:
            pass

        # è¿”å›ç»“æœæ‘˜è¦
        summary = f"""âœ… å°çº¢ä¹¦å¸–å­æ•°æ®é‡‡é›†å®Œæˆï¼

**å¸–å­æ ‡é¢˜**: {title}
**å¸–å­ç±»å‹**: {post_data.get('post_type', 'æœªçŸ¥')}
**äº’åŠ¨æ•°æ®**: ğŸ‘ {post_data.get('likes', 0)} | â­ {post_data.get('favorites', 0)} | ğŸ’¬ {post_data.get('comment_count', 0)}
**é‡‡é›†è¯„è®º**: {len(post_data.get('comments', []))} æ¡
**ä¿å­˜ä½ç½®**: {filepath}

---
æ‰§è¡Œæ—¥å¿—:
""" + "\n".join(results_log)

        return summary

    except Exception as e:
        # ç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿå…³é—­æµè§ˆå™¨
        try:
            close_browser.invoke({})
        except:
            pass
        return f"âŒ é‡‡é›†å¤±è´¥: {str(e)}\n\næ‰§è¡Œæ—¥å¿—:\n" + "\n".join(results_log)
