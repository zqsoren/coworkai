"""
Workflow Executor for Group Chat.

This module executes pre-defined workflows (generated by Supervisor),
allowing for deterministic, one-shot planning instead of iterative decision-making.
"""

import json
import asyncio
from typing import List, Dict, Any, Optional
from src.core.model_agent import ModelAgent


class WorkflowExecutor:
    """
    Executes a workflow plan generated by the Supervisor.
    
    Workflow format:
    {
      "plan_name": "...",
      "description": "...",
      "workflow": [
        {
          "step": 1,
          "step_name": "...",
          "executor_agent": "文案创作者",
          "executor_prompt": "...",
          "reviewer_agent": "审核员",  # or null
          "reviewer_prompt": "...",    # or null
          "max_revision_rounds": 3
        }
      ]
    }
    """
    
    def __init__(self, workflow: dict, agents: Dict[str, ModelAgent], history: List[Dict[str, Any]]):
        """
        Initialize the executor.
        
        Args:
            workflow: The workflow plan (dict with "workflow" key)
            agents: Dict of agent_name -> ModelAgent instances
            history: Initial conversation history
        """
        self.workflow = workflow
        self.agents = agents
        self.history = history.copy()  # Don't mutate original
        self.step_results: Dict[int, str] = {}  # {step_num: result}
    
    async def execute(self, on_step_complete=None) -> List[Dict[str, Any]]:
        """
        Execute the entire workflow.
        
        Args:
            on_step_complete: Optional async callback(step_result_dict)
        
        Returns:
            Updated conversation history with all agent responses
        """
        workflow_steps = self.workflow.get("workflow", [])
        
        import time
        def log_debug(msg):
            try:
                with open("backend_debug.log", "a", encoding="utf-8") as f:
                    f.write(f"[{time.strftime('%H:%M:%S')}] {msg}\n")
            except: pass

        log_debug(f"\n[WorkflowExecutor] Starting workflow: {self.workflow.get('plan_name', 'Untitled')}")
        log_debug(f"[WorkflowExecutor] Total steps: {len(workflow_steps)}")
        
        for step_config in workflow_steps:
            log_debug(f"[WorkflowExecutor] Executing Step {step_config.get('step')}...")
            try:
                result = await self._execute_step(step_config)
                self.step_results[step_config["step"]] = result
                
                # Trigger callback
                if on_step_complete:
                    # We might want to pass the last added message(s)
                    # For simplicity, let's pass the step info and result
                    step_data = {
                        "step": step_config["step"],
                        "agent_name": step_config["executor_agent"],
                        "content": result,
                        "timestamp": time.time()
                    }
                    if asyncio.iscoroutinefunction(on_step_complete):
                        await on_step_complete(step_data)
                    else:
                        on_step_complete(step_data)
                        
            except Exception as e:
                log_debug(f"[WorkflowExecutor] Step {step_config.get('step')} Failed: {e}")
                import traceback
                log_debug(traceback.format_exc())
                self.history.append({
                    "role": "assistant", 
                    "name": "System", 
                    "content": f"Critical Error in Step {step_config.get('step')}: {e}"
                })
                break
        
        log_debug(f"[WorkflowExecutor] Workflow completed!")
        return self.history
    
    async def _execute_step(self, step_config: dict) -> str:
        """
        Execute one workflow step, with optional review/revision loop.
        
        Args:
            step_config: Step configuration from workflow
        
        Returns:
            Final approved result for this step
        """
        step_num = step_config["step"]
        step_name = step_config.get("step_name", f"Step {step_num}")
        executor_name = step_config["executor_agent"]
        reviewer_name = step_config.get("reviewer_agent")
        max_rounds = step_config.get("max_revision_rounds", 0)
        
        print(f"\n{'='*60}")
        print(f"[Step {step_num}] {step_name}")
        print(f"[Executor] {executor_name}")
        if reviewer_name:
            print(f"[Reviewer] {reviewer_name} (max {max_rounds} revisions)")
        print(f"{'='*60}\n")
        
        # Get agent instances
        executor_agent = self.agents.get(executor_name)
        if not executor_agent:
            error_msg = f"[ERROR] Executor agent '{executor_name}' not found!"
            print(error_msg)
            self.history.append({
                "role": "assistant",
                "name": "System",
                "content": error_msg
            })
            return error_msg
        
        reviewer_agent = self.agents.get(reviewer_name) if reviewer_name else None
        
        # Initial executor prompt (with placeholders filled)
        executor_prompt = self._fill_placeholders(
            step_config["executor_prompt"],
            step_num
        )
        
        # Revision loop
        for round_num in range(max_rounds + 1):
            round_label = f"Round {round_num + 1}/{max_rounds + 1}" if max_rounds > 0 else "Execution"
            print(f"[{step_name}] {round_label}")
            
            # Execute
            result = await executor_agent.execute_with_context(
                executor_prompt,
                self.history
            )
            
            print(f"[{executor_name}] Output: {result[:100]}...")
            
            self.history.append({
                "role": "assistant",
                "name": executor_name,
                "content": result
            })
            
            # Review (if reviewer exists)
            if reviewer_agent and step_config.get("reviewer_prompt"):
                reviewer_prompt = self._fill_placeholders(
                    step_config["reviewer_prompt"],
                    step_num,
                    step_result=result
                )
                
                review = await reviewer_agent.execute_with_context(
                    reviewer_prompt,
                    self.history
                )
                
                print(f"[{reviewer_name}] Review: {review[:100]}...")
                
                self.history.append({
                    "role": "assistant",
                    "name": reviewer_name,
                    "content": review
                })
                
                # Check approval
                if "APPROVED" in review.upper():
                    print(f"[{reviewer_name}] ✓ APPROVED")
                    break
                elif round_num < max_rounds:
                    # Extract feedback and prepare revision
                    print(f"[{reviewer_name}] ✗ REJECTED, requesting revision...")
                    feedback = review.replace("REJECTED:", "").replace("REJECTED", "").strip()
                    executor_prompt = f"""修改意见：{feedback}

原内容：
{result}

请根据审核意见进行修改。"""
                else:
                    # Max rounds reached, force accept
                    print(f"[{reviewer_name}] ⚠ Max revisions reached, force accepting")
                    break
            else:
                # No reviewer, accept immediately
                print(f"[{step_name}] ✓ No review required")
                break
        
        print(f"[Step {step_num}] Completed\n")
        return result
    
    def _fill_placeholders(
        self, 
        prompt: str, 
        current_step: int, 
        step_result: Optional[str] = None
    ) -> str:
        """
        Replace placeholders in prompt template with actual values.
        
        Supported placeholders:
        - {user_input}: Original user request
        - {step_N_result}: Result from step N (e.g., {step_1_result})
        - {step_result}: Current step's execution result (for reviewer prompts)
        
        Args:
            prompt: Prompt template with placeholders
            current_step: Current step number (for logging)
            step_result: Optional current step result (for reviewer)
        
        Returns:
            Prompt with placeholders replaced
        """
        filled = prompt
        
        # {user_input} - Original user request
        user_msg = next(
            (m["content"] for m in self.history if m["role"] == "user"),
            ""
        )
        filled = filled.replace("{user_input}", user_msg)
        
        # {step_N_result} - Results from previous steps
        for step_num, result in self.step_results.items():
            placeholder = f"{{step_{step_num}_result}}"
            filled = filled.replace(placeholder, result)
        
        # {step_result} - Current step result (for reviewer)
        if step_result:
            filled = filled.replace("{step_result}", step_result)
        
        return filled
    
    def get_step_results(self) -> Dict[int, str]:
        """Get all step results."""
        return self.step_results.copy()
    
    def get_history(self) -> List[Dict[str, Any]]:
        """Get the complete execution history."""
        return self.history.copy()
